# Artifacts Directory

This directory stores intermediate and publication-ready outputs generated by the analysis pipeline.

```
artifacts/
├── examples/           # Sample metrics used for regression testing and documentation
├── interpretability/   # Attention heatmaps, expert traces, gradient attributions
├── publish/            # Tables and figures aggregated by `make publish`
├── publish.tar.gz      # Compressed bundle created by `make publish`
└── benchmarks/         # JSON reports from `src.analysis.benchmark`
```

## Reproducing Artifacts

Use the following workflow to regenerate the canonical outputs:

1. `python -m src.cli training.epochs=1 training.device=cpu`
2. `python -m src.analysis.interpretability --output-dir artifacts/interpretability`
3. `make publish`

The `publish` target assembles tables (`scripts/export_tables.py`) and figures (`scripts/export_figures.py`) using metrics stored in `artifacts/examples/metrics.csv`, then archives them in `artifacts/publish.tar.gz` for distribution.
